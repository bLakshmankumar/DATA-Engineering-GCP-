MySQL Migration: VM ‚Üí Cloud SQL (Export & Import) :
===================================================
Big Picture (Simple Theory)
Imagine we already have:
------------------------
  A VM
    MySQL installed on the VM
  Data inside MySQL:
    Databases
    Tables
    Views
    Functions / Procedures
  Goal:
   üëâ Move all MySQL data from VM to Cloud SQL

Methods for migration :
========================
  > Manual (Export & Import)  [Which is just used for POC's and not recommended]
  > DMS (Database Migration Service) [Recommended]
 Right now we focus on Manual method.

# What is Manual Migration (Export & Import)?
=============================================
  Manual migration means:
    Export data from source MySQL
    Store it as a dump file
    Upload dump to GCS
    Import dump into Cloud SQL

 When should we use Manual Method?
 ---------------------------------
   ‚úî Small / medium databases
   ‚úî One-time migration 
   ‚úî Minimal downtime acceptable
   ‚úî Simple MySQL versions
   ‚ùå Not good for:
       Large databases
       Near-zero downtime requirements
Real-time Flow :
----------------
  MySQL on VM 
   ‚îÄ‚îÄ(mysqldump)‚îÄ‚îÄ‚ñ∂ Dump file (.sql) 
   ‚îÄ‚îÄ(upload)‚îÄ‚îÄ‚ñ∂ Google Cloud Storage (GCS) 
   ‚îÄ‚îÄ(Cloud SQL import)‚îÄ‚îÄ‚ñ∂ Cloud SQL (MySQL)
Simple explanation : 
--------------------
  mysqldump exports data from VM MySQL
  Dump file is uploaded to GCS
  Cloud SQL import pulls data from GCS into Cloud SQL

1. Lets Step-by-Step Manual Migration (REALTIME) :
=================================================
  STEP 0Ô∏è‚É£ Prerequisites :
  -----------------------
    ‚úî VM has MySQL running
    ‚úî Cloud SQL MySQL instance created
    ‚úî GCS bucket created
    ‚úî Network connectivity
    ‚úî Permissions:
        VM ‚Üí GCS access
        Cloud SQL ‚Üí GCS access
   STEP 1Ô∏è‚É£ Export data from MySQL on VM :
   ---------------------------------------
     Login to VM :
     -------------
        ssh user@vm-ip
     Export single database (example) :
     ----------------------------------
      mysqldump -u root -p \
      --routines --triggers --events \
      orders_db > orders_db.sql

     Export ALL databases (Recommended) :
     ------------------------------------
       mysqldump -u root -p \
       --routines \
       --triggers \
       --events \
       --databases db1 db2 > full_dump.sql
      What this includes: 
      --------------------
        Option	              Includes
      --routines	   Stored functions & procedures
      --triggers	            Triggers
        --events	             Events
      --databases	        DB structure + data
     üëâ This covers tables, views, functions

   STEP 2Ô∏è‚É£ Verify dump file :
   ---------------------------
     ls -lh orders_db.sql
    üëâ Make sure file is created and non-zero size

   STEP 3Ô∏è‚É£ Upload dump to GCS :
   -----------------------------
     Create GCS bucket (if not exists) 
        gsutil mb gs://mysql-migration-bucket
     Upload dump file 
        gsutil cp orders_db.sql gs://mysql-migration-bucket/

   STEP 4Ô∏è‚É£ Prepare Cloud SQL :
   ---------------------------
    ‚úî Cloud SQL MySQL instance running
    ‚úî Database exists (or let import create it)
    ‚úî Enough storage
    ‚úî Same or higher MySQL version

   STEP 5Ô∏è‚É£ Import dump into Cloud SQL :
   ------------------------------------
     Run from Cloud Shell or local machine: 
       gcloud sql import sql orders-db-prod \
       gs://mysql-migration-bucket/orders_db.sql \
       --database=orders_db
     > What happens internally:
     --------------------------
         Cloud SQL pulls file from GCS
         Executes SQL statements
         Creates:
           Tables
           Views
           Functions
           Data

     STEP 6Ô∏è‚É£ Monitor import status :
     --------------------------------
       gcloud sql operations list --instance=orders-db-prod Or check in "GCP Console ‚Üí Cloud SQL ‚Üí Operations"

     STEP 7Ô∏è‚É£ Validate migration :
     -----------------------------
       Connect to Cloud SQL:
         gcloud sql connect orders-db-prod --user=root
       Run :
         SHOW DATABASES;
         USE orders_db;
         SHOW TABLES;
         SELECT COUNT(*) FROM orders;
         SHOW FUNCTION STATUS;
         SHOW FULL TABLES WHERE Table_type = 'VIEW';
       ‚úî Data verified
       ‚úî Migration complete 
   
  Note : Downtime in Manual Migration (Important)
  -----------------------------------------------
   No new data should be written to the source database while you are taking the dump.
    ‚ùå During export:
         Writes should be stopped
         Otherwise data mismatch
    üëâ Usually:
         Stop app
         Take dump
         Import
         Start app


2. DMS (Database Migration Service) [Important and automatic approach]: 
=======================================================================
    Migrating MySQL on VM ‚Üí Cloud SQL using DMS (Database Migration Service) :
    --------------------------------------------------------------------------
       First, what is DMS in simple words?
         Database Migration Service (DMS) is a managed GCP service that:
           Migrates databases with minimal or zero downtime
           Handles schema + data
           Can do continuous replication (CDC)
           Avoids manual dump/import pain
       üëâ Think of it as Google-managed mysqldump + replication + monitoring, all in one UI.
   
    Example Your Current Setup : [Goal: Move everything safely]
    ----------------------------
       VM
        ‚îî‚îÄ‚îÄ MySQL (Databases, Tables, Views, Functions)
       Target
        ‚îî‚îÄ‚îÄ Cloud SQL (MySQL)

    Migration Methods Recap :
    --------------------------
         Method	             Downtime             	Automation-Use case
   Manual (dump/import)      	High               	Low	Small DB, dev/test
         DMS	             Low / Zero	High	      Production workloads ‚úÖ

  # Now let‚Äôs deep dive into DMS :
  ================================ 
     DMS Migration ‚Äì High-Level Flow :
     ---------------------------------
       MySQL on VM
         |
         | (initial load)
         v
      Cloud SQL (MySQL)
         ^
         |
         | (continuous replication)
     
      DMS works in 2 phases:
        Initial Load ‚Äì copy existing data
        Continuous Sync (CDC) ‚Äì keep source & target in sync
  
    # STEP-BY-STEP DMS PROCESS (REALTIME) : 
    =======================================
      STEP 1: Prepare Source MySQL (VM) :
      -----------------------------------
        Why?
          DMS reads binary logs (binlogs) to track changes.
        Required settings in MySQL :
          server-id=1
          log-bin=mysql-bin
          binlog_format=ROW
          binlog_row_image=FULL
       
        What this means :
        -----------------
          log-bin: Enables change tracking
          ROW: Records actual row changes (required)
          FULL: Captures complete row data
        Restart MySQL after change :
        ----------------------------
          sudo systemctl restart mysql

      STEP 2: Create Migration User on VM :
      -------------------------------------
        DMS needs a user with replication privileges.
          CREATE USER 'dms_user'@'%' IDENTIFIED BY 'StrongPassword';
          GRANT SELECT, RELOAD, SHOW DATABASES, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'dms_user'@'%';
          FLUSH PRIVILEGES;
        Interview tip:
          DMS never uses root ‚Äì always a limited user.

      STEP 3: Create Cloud SQL (Target) :
      -----------------------------------
        Create Cloud SQL MySQL instance:
          Same or higher MySQL version
          Enough CPU, RAM, storage
          Private IP preferred (prod)
         ‚ö†Ô∏è Cloud SQL must be EMPTY (no tables, no schema)

      STEP 4: Open Network Connectivity :
      -----------------------------------
        DMS must reach your VM.
        Options:
          Public IP + authorized networks
          OR Private IP + VPC peering (best practice)
          Ensure:
            MySQL port 3306 is reachable

     STEP 5: Create Migration Job (DMS UI) :
     ----------------------------------------
       Go to : 
         GCP Console ‚Üí Database Migration ‚Üí Create Migration Job
       Option 1: Migration Job Type :
       ------------------------------
          Option	                    Meaning
         One-time                	One copy only
        Continuous ‚úÖ       	Initial load + ongoing sync (recommended)
       Option 2: Source Database :
       ---------------------------
         Fill:
           Source type: MySQL
           Hostname/IP: VM IP
           Port: 3306
           Username: dms_user
           Password
         Click Test Connection
       Option 3: Destination Database :
       --------------------------------
         Choose Cloud SQL instance
         Select MySQL
         Region must match latency expectations
       Option 4: Migration Mode :
       --------------------------
           Mode	                 What it migrates
       Schema only            	Just tables, views
        Data only	                 Only rows
       Schema + Data ‚úÖ        Everything [Recommended]
       Option 5: Object Selection :
       ----------------------------
       You can:
         Migrate all databases
         OR select specific databases/tables
        üìå Useful for partial migrations.
   
     STEP 6: Start Migration (Initial Load) :
     ----------------------------------------
       DMS now:
         Reads schemas
         Copies tables
         Migrates views & functions
         Loads data into Cloud SQL
      üí° Application can stay RUNNING
       Changes are tracked via binlogs

     STEP 7: Continuous Replication (CDC) :
     --------------------------------------
       After initial load:
         DMS reads binlogs
         Applies INSERT / UPDATE / DELETE
         Keeps Cloud SQL in sync
       üìä You can monitor:
            Replication lag
            Errors
            Progress
     
     STEP 8: Cutover (Final Switch) :
     --------------------------------
       When ready to go live:
          Proper Cutover Steps: 
            1. Stop application writes
            2. Wait for replication lag = 0
            3. Promote Cloud SQL
            4. Point app to Cloud SQL
            5. Start application
       Downtime = few seconds/minutes

   Interview Answer (Short & Clear) :
   ----------------------------------
     We migrate MySQL from VM to Cloud SQL using Database Migration Service. First, we enable binlogs on the source and create a replication user. 
     Then we create a continuous migration job in DMS, which performs an initial data load followed by continuous replication using binlogs. 
     During cutover, we briefly stop application writes, wait for replication lag to reach zero, and switch the application to Cloud SQL, achieving near-zero downtime.‚Äù
  
   What is mean by  binlogs :
   --------------------------
     Binary logs (binlogs) are enabled on the source database to capture all data changes (INSERT, UPDATE, DELETE). 
     Database Migration Service reads these binlogs using a replication user to continuously replicate changes from the source to Cloud SQL, ensuring data stays in sync until cutover.

  What is mean by cutover : 
  -------------------------
    Cutover is the final step in migration where application writes are stopped, data sync is completed, and the application is switched from the source database to the target database.

3. Migration using DataFlow : 
==============================

